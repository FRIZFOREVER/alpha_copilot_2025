# LLM mode selection
# Allowed values:
#  - ollama: uses local models pulled by the container (default).
#  - huggingface: calls HuggingFace Inference API; skips local model downloads and requires secrets.
#  - openrouter: sends requests through OpenRouter; skips local model downloads and requires secrets.
LLM_MODE=ollama

# Ollama
## Модели, официально поддерживаемые ollama: https://ollama.com/search
## Модели, поддерживаемые HuggingFace: https://huggingface.co/
## Примечание: На старых видеокартах Ollama поддерживает только модели формата GGUF
## Если не уверены в выборе модели, раскомментируйте один из блоков ниже с уже прописанными моделями
## И закоментируйте неустановленные

## Это рекомендованный уровень моделей для стабильно качественный
## Однако малый уровень квантинизации (Q8_0) имеет меньшую скорость вычислений
# OLLAMA_REASONING_MODEL=hf.co/Qwen/Qwen3-14B-GGUF:Q8_0

## Это минимально необходимый уровень модели, обеспечивающий быструю генерацию
## и быстрый поиск в интернете, однако значительно хуже понимает рабочий котекст задач
# OLLAMA_REASONING_MODEL=qwen3:14b

OLLAMA_REASONING_MODEL=YOUR_REASONING_MODEL

## Рекомендую использование минимально доступного Эмбеддера
## Из семейства Qwen3
# OLLAMA_EMBEDDING_MODEL=qwen3-embedding:0.6b

OLLAMA_EMBEDDING_MODEL=YOUR_EMBEDDING_MODEL

# External providers (used only when LLM_MODE is not 'ollama')
# Ключи должны быть установлены перед запуском, чтобы провайдер работал без локальных загрузок моделей.
HUGGINGFACE_API_KEY=YOUR_HUGGINGFACE_API_KEY
HUGGINGFACE_BASE_URL=https://api-inference.huggingface.co/models/
OPENROUTER_API_KEY=YOUR_OPENROUTER_API_KEY
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1/

# Backend
# Данный ключ может понадобиться, если нет возможности локально
# Развернуть контейнер с Whisper'om
# Этот ключ будет использован при отсутствии соединения с recognizer-service
# Для попытки подключения к внешнему API
# Для его получения свяжитесь с капитаном команды в телеграмме t.me/FRIZFOREVER
ASSEMBLYAI_API_KEY=YOUR_ASSEMLYAI_KEY
